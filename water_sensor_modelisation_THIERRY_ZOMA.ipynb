{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"spark ML\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = spark.read.csv(\"./training_data.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+-----+---+---+------+---+----+-----------------+------------+--------------+---------+----------+-------+\n",
      "| V1|  V2|   V3|   V4| V5| V6|    V7| V8| PDC|          Contrat|    localite|MeterMatricule|Millesime|        T0|  Label|\n",
      "+---+----+-----+-----+---+---+------+---+----+-----------------+------------+--------------+---------+----------+-------+\n",
      "|152|0.99|0.897| 1.67|  5| 54| 37743|  3|  11|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|08/12/2017|STOPPED|\n",
      "| 76|   1|0.993|    0|  0|239|413425|  1|1701|NEUVY-LES-MOULINS|       NEUVY|            NA|    C13FA|29/10/2016|STOPPED|\n",
      "| 71|0.32|0.965| 8.38| 53| 45| 85193|  8|1802|NEUVY-LES-MOULINS|       NEUVY|            NA|    C13FA|28/11/2016|STOPPED|\n",
      "| 92|0.84|0.871| 4.61| 77| 49|263697| 36|2201|NEUVY-LES-MOULINS|       NEUVY|            NA|    C13FA|29/10/2017|STOPPED|\n",
      "| 91|0.31|0.189|28.95|126| 13| 90206| 27|5201|NEUVY-LES-MOULINS|       NEUVY|            NA|    C12FA|19/08/2018|STOPPED|\n",
      "| 65|0.74|0.451|12.57| 60| 33|187459|  7|5901|NEUVY-LES-MOULINS|       NEUVY|            NA|    C13FA|30/09/2016|STOPPED|\n",
      "| 63|0.08|0.185| 43.5|166| 21|185199|  8|6801|NEUVY-LES-MOULINS|       NEUVY|            NA|    C13FA|01/05/2017|STOPPED|\n",
      "| 62|0.12|0.049|  215|426|  2|  5338|  2| 108|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|11/09/2018|STOPPED|\n",
      "|122|0.99|0.635|   38|114|191|113709|  3| 113|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|03/08/2018|STOPPED|\n",
      "|238|0.78|0.943|  5.8| 19|149|103712|  5| 144|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|21/03/2018|STOPPED|\n",
      "| 69|0.47|0.743|13.67| 37|220| 89662|  9| 162|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|26/08/2018|STOPPED|\n",
      "| 77|0.83|0.571|  9.2| 82| 83| 51327| 15| 206|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|14/09/2018|STOPPED|\n",
      "| 85|0.24|0.304|   86|188| 15| 19088|  3| 240|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|03/04/2018|STOPPED|\n",
      "| 80|0.49|0.636| 6.45| 73| 40| 36604| 22| 255|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|15/08/2018|STOPPED|\n",
      "|120|0.72|0.981| 3.29| 20| 78| 24936|  7| 283|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|14/03/2018|STOPPED|\n",
      "|146|0.08|0.106|83.33|160| 13| 10296|  3| 286|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C16FA|05/06/2018|STOPPED|\n",
      "|111|0.62|0.405| 7.67| 54| 64|162579| 27| 301|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|04/11/2018|STOPPED|\n",
      "| 69|0.67|0.588| 9.64| 65| 38| 97225| 14| 351|        LA FLECHE|    LAFLECHE|            NA|    C17FA|26/12/2018|STOPPED|\n",
      "| 78|0.93|0.911|  0.7|  4| 54| 38170| 10| 375|        LA FLECHE|    LAFLECHE|            NA|    C17FA|29/06/2018|STOPPED|\n",
      "| 73| 0.6| 0.25| 16.8| 40| 45| 30466|  5| 380|     LIANCOURTOIS|LIANCOURTOIS|            NA|    C17FA|06/02/2018|STOPPED|\n",
      "+---+----+-----+-----+---+---+------+---+----+-----------------+------------+--------------+---------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169078"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  Label|count(1)|\n",
      "+-------+--------+\n",
      "|BLOCKED|    1364|\n",
      "|STOPPED|  167714|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy(\"Label\").agg(f.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- V1: string (nullable = true)\n",
      " |-- V2: string (nullable = true)\n",
      " |-- V3: string (nullable = true)\n",
      " |-- V4: string (nullable = true)\n",
      " |-- V5: string (nullable = true)\n",
      " |-- V6: string (nullable = true)\n",
      " |-- V7: string (nullable = true)\n",
      " |-- V8: string (nullable = true)\n",
      " |-- PDC: string (nullable = true)\n",
      " |-- Contrat: string (nullable = true)\n",
      " |-- localite: string (nullable = true)\n",
      " |-- MeterMatricule: string (nullable = true)\n",
      " |-- Millesime: string (nullable = true)\n",
      " |-- T0: string (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute V9 from V7 and Millesime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_features = [\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]\n",
    "millesime_0 = ['C10FA','C10LA','C10SA', 'C11FA','C11LA','C11SA']\n",
    "millesime_1 = ['D16BU', 'Z12ER', 'C07AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.withColumn(\n",
    "    'V9',\n",
    "    f.when(\n",
    "        (training_data['Millesime'].isin(millesime_0)) & (f.length(training_data['V7'])>3),\n",
    "        0\n",
    "    ).otherwise(\n",
    "        f.when(\n",
    "            training_data['Millesime'].isin(millesime_1),\n",
    "            1\n",
    "        ).otherwise(2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+\n",
      "|    V7|Millesime| V9|\n",
      "+------+---------+---+\n",
      "|135665|    C11FA|  0|\n",
      "|410287|    C11FA|  0|\n",
      "|187007|    C11FA|  0|\n",
      "|350368|    C11FA|  0|\n",
      "|314965|    C11FA|  0|\n",
      "+------+---------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.select(['V7','Millesime', 'V9']).where(training_data.V9 == 0).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(V9=1), Row(V9=2), Row(V9=0)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.select(\"V9\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target values count by locality type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------+\n",
      "|    localite|  Label|count(1)|\n",
      "+------------+-------+--------+\n",
      "| LEMANSMETRO|STOPPED|    1049|\n",
      "|LIANCOURTOIS|STOPPED|     562|\n",
      "|   LYONNAISE|BLOCKED|    1153|\n",
      "|     OCEAVHF|BLOCKED|     190|\n",
      "|       SIEVA|STOPPED|    1245|\n",
      "|  CHAMPFLEUR|STOPPED|     178|\n",
      "|    OMFLEURY|STOPPED|     231|\n",
      "|       NEUVY|STOPPED|      34|\n",
      "|       CREMA|STOPPED|       2|\n",
      "|      SIDERM|BLOCKED|       8|\n",
      "|  CHAMPFLEUR|BLOCKED|       1|\n",
      "|    FLORENCE|STOPPED|      54|\n",
      "|   CALEDONIE|STOPPED|       1|\n",
      "|    AGUR-LCF|STOPPED|    2201|\n",
      "|     OCEAVHF|STOPPED|   39792|\n",
      "|      AREZZO|STOPPED|       1|\n",
      "|   POLYNESIE|STOPPED|       2|\n",
      "|     NICEREA|STOPPED|       3|\n",
      "|    LAFLECHE|STOPPED|     290|\n",
      "|MONTDEMARSAN|STOPPED|     652|\n",
      "+------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_label_locality = training_data.groupBy([\"localite\", \"Label\"]).agg(f.count(\"*\"))\n",
    "agg_label_locality.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.filter(\n",
    "    (training_data.localite == \"LYONNAISE\") \n",
    "    &\n",
    "    (training_data.Label == \"BLOCKED\")\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining a function for column casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_col(df, column, type=\"string\"):\n",
    "    if isinstance(column, list):\n",
    "        for c in column:\n",
    "            df = df.withColumn(c, df[c].cast(type))\n",
    "        return df\n",
    "    else:\n",
    "        return df.withColumn(column, df[column].cast(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- V1: integer (nullable = true)\n",
      " |-- V2: integer (nullable = true)\n",
      " |-- V3: integer (nullable = true)\n",
      " |-- V4: integer (nullable = true)\n",
      " |-- V5: integer (nullable = true)\n",
      " |-- V6: integer (nullable = true)\n",
      " |-- V7: integer (nullable = true)\n",
      " |-- V8: integer (nullable = true)\n",
      " |-- PDC: string (nullable = true)\n",
      " |-- Contrat: string (nullable = true)\n",
      " |-- localite: string (nullable = true)\n",
      " |-- MeterMatricule: string (nullable = true)\n",
      " |-- Millesime: string (nullable = true)\n",
      " |-- T0: string (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- V9: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = cast_col(training_data, consumption_features, \"integer\")\n",
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+------+---+---+-------+\n",
      "| V1| V2| V3| V4| V5| V6|    V7| V8| V9|  Label|\n",
      "+---+---+---+---+---+---+------+---+---+-------+\n",
      "|152|  0|  0|  1|  5| 54| 37743|  3|  2|STOPPED|\n",
      "| 76|  1|  0|  0|  0|239|413425|  1|  2|STOPPED|\n",
      "| 71|  0|  0|  8| 53| 45| 85193|  8|  2|STOPPED|\n",
      "| 92|  0|  0|  4| 77| 49|263697| 36|  2|STOPPED|\n",
      "| 91|  0|  0| 28|126| 13| 90206| 27|  2|STOPPED|\n",
      "| 65|  0|  0| 12| 60| 33|187459|  7|  2|STOPPED|\n",
      "| 63|  0|  0| 43|166| 21|185199|  8|  2|STOPPED|\n",
      "| 62|  0|  0|215|426|  2|  5338|  2|  2|STOPPED|\n",
      "|122|  0|  0| 38|114|191|113709|  3|  2|STOPPED|\n",
      "|238|  0|  0|  5| 19|149|103712|  5|  2|STOPPED|\n",
      "| 69|  0|  0| 13| 37|220| 89662|  9|  2|STOPPED|\n",
      "| 77|  0|  0|  9| 82| 83| 51327| 15|  2|STOPPED|\n",
      "| 85|  0|  0| 86|188| 15| 19088|  3|  2|STOPPED|\n",
      "| 80|  0|  0|  6| 73| 40| 36604| 22|  2|STOPPED|\n",
      "|120|  0|  0|  3| 20| 78| 24936|  7|  2|STOPPED|\n",
      "|146|  0|  0| 83|160| 13| 10296|  3|  2|STOPPED|\n",
      "|111|  0|  0|  7| 54| 64|162579| 27|  2|STOPPED|\n",
      "| 69|  0|  0|  9| 65| 38| 97225| 14|  2|STOPPED|\n",
      "| 78|  0|  0|  0|  4| 54| 38170| 10|  2|STOPPED|\n",
      "| 73|  0|  0| 16| 40| 45| 30466|  5|  2|STOPPED|\n",
      "+---+---+---+---+---+---+------+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consumption_features_df = training_data.select(consumption_features+[\"Label\"])\n",
    "consumption_features_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  Label|count(1)|\n",
      "+-------+--------+\n",
      "|BLOCKED|    1364|\n",
      "|STOPPED|  167714|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy(\"Label\").agg(f.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We deal with imbalanced dataset.\n",
    "let's balanced it before going ahead for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_data = training_data.filter(f.col(\"Label\") == \"BLOCKED\")\n",
    "stopped_data = training_data.filter(f.col(\"Label\") == \"STOPPED\")\n",
    "\n",
    "# Subsample the STOPPED class\n",
    "stopped_data_sampled = stopped_data.sample(withReplacement=False, fraction=0.02, seed=2000)\n",
    "\n",
    "balanced_data = blocked_data.union(stopped_data_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=consumption_features, outputCol=\"features\")\n",
    "balanced_data = assembler.transform(balanced_data)\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"Label\", outputCol=\"label\")\n",
    "balanced_data = label_indexer.fit(balanced_data).transform(balanced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding:\n",
    "- BLOCKED: 0  \n",
    "- STOPPED: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[109.0,0.0,0.0,2....|  1.0|\n",
      "|[138.0,0.0,0.0,0....|  1.0|\n",
      "|(9,[0,6],[258.0,1...|  1.0|\n",
      "|[73.0,0.0,0.0,0.0...|  1.0|\n",
      "|[274.0,1.0,0.0,0....|  1.0|\n",
      "|[72.0,0.0,0.0,102...|  1.0|\n",
      "|(9,[0,6,8],[181.0...|  1.0|\n",
      "|[178.0,1.0,1.0,0....|  1.0|\n",
      "|[25.0,0.0,0.0,4.0...|  1.0|\n",
      "|[95.0,1.0,0.0,2.0...|  1.0|\n",
      "|[100.0,0.0,0.0,10...|  1.0|\n",
      "|[52.0,0.0,0.0,0.0...|  1.0|\n",
      "|(9,[0,6],[279.0,4...|  1.0|\n",
      "|(9,[0,6],[279.0,5...|  1.0|\n",
      "|[119.0,0.0,0.0,7....|  1.0|\n",
      "|(9,[0,6],[279.0,1...|  1.0|\n",
      "|[116.0,0.0,0.0,2....|  1.0|\n",
      "|[71.0,1.0,0.0,2.0...|  1.0|\n",
      "|[162.0,0.0,0.0,8....|  1.0|\n",
      "|[257.0,0.0,0.0,8....|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = balanced_data.select(\"features\", \"label\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", elasticNetParam=0.5)\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "train_predictions = lr_model.transform(train_data)\n",
    "test_predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_name, train_predictions, test_predictions):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    bin_avaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "    # Accuracy\n",
    "    train_acc = evaluator.evaluate(train_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "    test_acc = evaluator.evaluate(test_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "    # F1-score\n",
    "    train_f1 = evaluator.evaluate(train_predictions, {evaluator.metricName: \"f1\"})\n",
    "    test_f1 = evaluator.evaluate(test_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "    # AUC\n",
    "    train_auc = bin_avaluator.evaluate(train_predictions)\n",
    "    test_auc = bin_avaluator.evaluate(test_predictions)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc\n",
    "        }\n",
    "# print(f\"Train Accuracy: {train_acc}, Train F1-Score: {train_f1}, Train AUC: {train_auc}\")\n",
    "# print(f\"Test Accuracy: {test_acc}, Test F1-Score: {test_f1}, Test AUC: {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Logistic regresstion', 'train_accuracy': 0.8251133031191682, 'test_accuracy': 0.8110072689511942, 'train_f1': 0.8222438439400226, 'test_f1': 0.808016474890826, 'train_auc': 0.8553104677121898, 'test_auc': 0.8430894646227887}\n"
     ]
    }
   ],
   "source": [
    "lr_metrics = eval(\"Logistic regresstion\", train_predictions, test_predictions)\n",
    "print(lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=5)\n",
    "dc_model = dc.fit(train_data)\n",
    "\n",
    "train_predictions = dc_model.transform(train_data)\n",
    "test_predictions = dc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Decision Tree', 'train_accuracy': 0.8800319914689416, 'test_accuracy': 0.8681204569055037, 'train_f1': 0.8768901108847249, 'test_f1': 0.8656174950523802, 'train_auc': 0.6707551617510434, 'test_auc': 0.6186344873363895}\n"
     ]
    }
   ],
   "source": [
    "dc_metrics = eval(\"Decision Tree\", train_predictions, test_predictions)\n",
    "print(dc_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=20)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "train_predictions = rf_model.transform(train_data)\n",
    "test_predictions = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Random Forest', 'train_accuracy': 0.8829645427885897, 'test_accuracy': 0.8712357217030114, 'train_f1': 0.8789910473219407, 'test_f1': 0.8673075270621999, 'train_auc': 0.9258361412704355, 'test_auc': 0.929766744798689}\n"
     ]
    }
   ],
   "source": [
    "rf_metrics = eval(\"Random Forest\", train_predictions, test_predictions)\n",
    "print(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "gb_model = gb.fit(train_data)\n",
    "\n",
    "train_predictions = gb_model.transform(train_data)\n",
    "test_predictions = gb_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Gradient Boosting', 'train_accuracy': 0.8938949613436417, 'test_accuracy': 0.8764278296988577, 'train_f1': 0.8912704342614751, 'test_f1': 0.8742399903157332, 'train_auc': 0.9483282374474814, 'test_auc': 0.9409550084009211}\n"
     ]
    }
   ],
   "source": [
    "gb_metrics = eval(\"Gradient Boosting\", train_predictions, test_predictions)\n",
    "print(gb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regresstion</td>\n",
       "      <td>0.825113</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.822244</td>\n",
       "      <td>0.808016</td>\n",
       "      <td>0.855310</td>\n",
       "      <td>0.843089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.880032</td>\n",
       "      <td>0.868120</td>\n",
       "      <td>0.876890</td>\n",
       "      <td>0.865617</td>\n",
       "      <td>0.670755</td>\n",
       "      <td>0.618634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.882965</td>\n",
       "      <td>0.871236</td>\n",
       "      <td>0.878991</td>\n",
       "      <td>0.867308</td>\n",
       "      <td>0.925836</td>\n",
       "      <td>0.929767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.893895</td>\n",
       "      <td>0.876428</td>\n",
       "      <td>0.891270</td>\n",
       "      <td>0.874240</td>\n",
       "      <td>0.948328</td>\n",
       "      <td>0.940955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  train_accuracy  test_accuracy  train_f1   test_f1  \\\n",
       "0  Logistic regresstion        0.825113       0.811007  0.822244  0.808016   \n",
       "1         Decision Tree        0.880032       0.868120  0.876890  0.865617   \n",
       "2         Random Forest        0.882965       0.871236  0.878991  0.867308   \n",
       "3     Gradient Boosting        0.893895       0.876428  0.891270  0.874240   \n",
       "\n",
       "   train_auc  test_auc  \n",
       "0   0.855310  0.843089  \n",
       "1   0.670755  0.618634  \n",
       "2   0.925836  0.929767  \n",
       "3   0.948328  0.940955  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = [lr_metrics, dc_metrics, rf_metrics, gb_metrics]\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the globals performances based on the differents metrics such as **Accuracy**, **f1-score** and **AUC**, we will choose `Gradient Boosting` that shows greats performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model to the current directory: gradient boosting model\n",
    "gb_model.write().overwrite().save(\"./bestmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = spark.read.csv(\"./dataset_sample_spark.csv\", sep=\";\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+---------+-----------+----------+-------------+--------------+----------------------------+\n",
      "|     sensor|servicePoint|   client|transmitter|      date|meterDiameter|volume_l_value|index_interpolated_d_l_value|\n",
      "+-----------+------------+---------+-----------+----------+-------------+--------------+----------------------------+\n",
      "|C04AE134021| 9,84588E+11|LYONNAISE|   C01E00D9|01/01/2019|           40|           0.0|                   5623306.0|\n",
      "|C04AE134021| 9,84588E+11|LYONNAISE|   C01E00D9|01/01/2020|           40|          95.0|                   5991416.0|\n",
      "|C04AE134021| 9,84588E+11|LYONNAISE|   C01E00D9|01/01/2021|           40|           7.0|                   6713307.5|\n",
      "|C04AE134021| 9,84588E+11|LYONNAISE|   C01E00D9|01/02/2019|           40|          15.0|                   5648016.0|\n",
      "|C04AE134021| 9,84588E+11|LYONNAISE|   C01E00D9|01/02/2020|           40|         339.0|                   6026507.0|\n",
      "+-----------+------------+---------+-----------+----------+-------------+--------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# suppression des doublons en gardant\n",
    "sample_data = sample_data.dropDuplicates([\"sensor\", \"servicePoint\", \"transmitter\", \"date\"])\n",
    "sample_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la consommation moyenne par diamètre de compteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------------+\n",
      "|     sensor|meterDiameter|   avg_consumption|\n",
      "+-----------+-------------+------------------+\n",
      "|C10FA046664|           15|116.76915487907694|\n",
      "|C08EB001382|           20| 99.49573222647919|\n",
      "|C09FA079673|           15| 1018.235997442455|\n",
      "|C10ED005356|           30| 629.8111048051459|\n",
      "|C08FA041975|           15| 60.94796407185634|\n",
      "|C09FA127701|           15|153.78950403690888|\n",
      "|C08FA085851|           15| 210.2792194642136|\n",
      "|C07AA092853|           15| 766.9642578125004|\n",
      "|C09FA030008|           15|  563.314566115702|\n",
      "|C04AE134021|           40|1529.3411509188334|\n",
      "+-----------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# consommation moyenne par diamètre\n",
    "avg_consumption_by_diameter = sample_data.groupBy([\"sensor\", \"meterDiameter\"]).agg(f.mean(\"volume_l_value\").alias(\"avg_consumption\"))\n",
    "avg_consumption_by_diameter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------------+\n",
      "|     sensor|meterDiameter|   avg_consumption|\n",
      "+-----------+-------------+------------------+\n",
      "|C09FA079673|           15| 1018.235997442455|\n",
      "|C10ED005356|           30| 629.8111048051459|\n",
      "|C07AA092853|           15| 766.9642578125004|\n",
      "|C09FA030008|           15|  563.314566115702|\n",
      "|C04AE134021|           40|1529.3411509188334|\n",
      "+-----------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gros compteur\n",
    "global_avg_consumption = sample_data.agg(f.mean(\"volume_l_value\")).collect()[0][0]\n",
    "gros_compteurs = avg_consumption_by_diameter.filter(f.col(\"avg_consumption\") > global_avg_consumption)\n",
    "gros_compteurs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V1|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2019-01-01|           0.0|730|\n",
      "|C04AE134021|2019-01-02|          61.0|730|\n",
      "|C04AE134021|2019-01-03|           7.0|949|\n",
      "|C04AE134021|2019-01-04|           5.0|949|\n",
      "|C04AE134021|2019-01-05|           3.0|949|\n",
      "|C04AE134021|2019-01-06|        1200.0|949|\n",
      "|C04AE134021|2019-01-07|        1076.0|945|\n",
      "|C04AE134021|2019-01-08|        2346.0|944|\n",
      "|C04AE134021|2019-01-09|        4533.0|943|\n",
      "|C04AE134021|2019-01-10|        1165.0|942|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. casting date format\n",
    "df = sample_data.withColumn(\"date\", f.to_date(f.col(\"date\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "# Calcul de T : date maximale pour chaque triplette unique [sensor, servicePoint, client]\n",
    "df_t = df.groupBy(\"sensor\", \"servicePoint\", \"client\").agg(\n",
    "    f.max(\"date\").alias(\"T\")\n",
    ")\n",
    "\n",
    "# Joindre T avec le DataFrame initial\n",
    "df = df.join(df_t, on=[\"sensor\", \"servicePoint\", \"client\"], how=\"left\")\n",
    "\n",
    "# 2. compute significant concumption column: where volume > 20.0 litters\n",
    "df = df.withColumn(\n",
    "    \"significant_consumption\",\n",
    "    f.when(f.col(\"volume_l_value\").cast(\"double\") > 20, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# 3 compute T0: max significant consumption date before current date \n",
    "window_spec_lag = Window.partitionBy(\"sensor\", \"servicePoint\").orderBy(\"date\").rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"T0\",\n",
    "    f.max(\n",
    "        f.when(\n",
    "            f.col(\"significant_consumption\") == 1,\n",
    "            f.col(\"date\")\n",
    "        )\n",
    "    ).over(window_spec_lag)\n",
    ")\n",
    "\n",
    "# compute v1\n",
    "df = df.withColumn(\n",
    "    \"V1\",\n",
    "    f.when(\n",
    "        f.col(\"T0\").isNotNull(),\n",
    "        f.datediff(\n",
    "            f.col(\"T\"),\n",
    "            f.col(\"T0\")\n",
    "        )\n",
    "    ).otherwise(730)\n",
    ")\n",
    "\n",
    "# # Afficher le résultat\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V1\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| V1|\n",
      "+---+\n",
      "|833|\n",
      "|496|\n",
      "|463|\n",
      "|148|\n",
      "|471|\n",
      "|858|\n",
      "|737|\n",
      "|623|\n",
      "|540|\n",
      "|392|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V1\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V2|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2021-08-08|           0.0|0.0|\n",
      "|C04AE134021|2021-08-07|           0.0|0.0|\n",
      "|C04AE134021|2021-08-06|           0.0|0.0|\n",
      "|C04AE134021|2021-08-05|           0.0|0.0|\n",
      "|C04AE134021|2021-08-04|           0.0|0.0|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(f.desc(\"date\"))\n",
    "\n",
    "# Trouver la dernière date avec une consommation significative\n",
    "df = df.withColumn(\n",
    "    \"last_significant_date\",\n",
    "    f.when(f.col(\"significant_consumption\") == 1, f.col(\"date\"))\n",
    ").withColumn(\n",
    "    \"last_significant_date\",\n",
    "    f.last(\"last_significant_date\", ignorenulls=True).over(window_spec)\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"T0\", f.last(\"last_significant_date\", ignorenulls=True).over(window_spec)\n",
    ")\n",
    "\n",
    "# Filtrer les 90 jours avant T0\n",
    "df = df.withColumn(\n",
    "    \"within_90_days\",\n",
    "    f.when(\n",
    "        (f.col(\"date\") <= f.col(\"T0\")) & (f.col(\"date\") > f.date_sub(f.col(\"T0\"), 90)),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Calculer le nombre de jours avec consommation non nulle dans les 90 jours avant T0\n",
    "df = df.withColumn(\n",
    "    \"non_null_days\",\n",
    "    f.when((f.col(\"within_90_days\") == 1) & (f.col(\"volume_l_value\") > 0), 1).otherwise(0)\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"total_non_null_days\", f.sum(\"non_null_days\").over(window_spec)\n",
    ")\n",
    "# Calculer v2\n",
    "df = df.withColumn(\n",
    "    \"v2\", f.col(\"total_non_null_days\") / 90\n",
    ")\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V2\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                 V2|\n",
      "+-------------------+\n",
      "| 7.2444444444444445|\n",
      "|  7.533333333333333|\n",
      "|  7.711111111111111|\n",
      "|  7.866666666666666|\n",
      "|  9.688888888888888|\n",
      "|0.18888888888888888|\n",
      "| 1.2666666666666666|\n",
      "| 1.7444444444444445|\n",
      "| 2.5444444444444443|\n",
      "|  4.877777777777778|\n",
      "+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V2\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V3|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2021-08-08|           0.0|0.0|\n",
      "|C04AE134021|2021-08-07|           0.0|0.0|\n",
      "|C04AE134021|2021-08-06|           0.0|0.0|\n",
      "|C04AE134021|2021-08-05|           0.0|0.0|\n",
      "|C04AE134021|2021-08-04|           0.0|0.0|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définir la période de 6 mois (183 jours) avant T0 - 90 jours\n",
    "df = df.withColumn(\n",
    "    \"within_183_days\",\n",
    "    f.when(\n",
    "        (f.col(\"date\") <= f.date_sub(f.col(\"T0\"), 90)) & \n",
    "        (f.col(\"date\") > f.date_sub(f.col(\"T0\"), 273)), \n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Calculer le nombre de jours avec consommation non nulle dans la période de 6 mois\n",
    "df = df.withColumn(\n",
    "    \"non_null_days_v3\",\n",
    "    f.when((f.col(\"within_183_days\") == 1) & (f.col(\"volume_l_value\") > 0), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"total_non_null_days_v3\", \n",
    "    f.sum(\"non_null_days_v3\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\"))\n",
    ")\n",
    "\n",
    "# Calculer v3\n",
    "df = df.withColumn(\n",
    "    \"v3\", f.col(\"total_non_null_days_v3\") / 183\n",
    ")\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V3\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+------------------+\n",
      "|     sensor|      date|volume_l_value|                V4|\n",
      "+-----------+----------+--------------+------------------+\n",
      "|C04AE134021|2019-01-01|           0.0|1.8918918918918919|\n",
      "|C04AE134021|2020-01-01|          95.0|1.8918918918918919|\n",
      "|C04AE134021|2021-01-01|           7.0|1.8918918918918919|\n",
      "|C04AE134021|2019-02-01|          15.0|1.8918918918918919|\n",
      "|C04AE134021|2020-02-01|         339.0|1.8918918918918919|\n",
      "+-----------+----------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les données sur une période d'un an avant T0\n",
    "df = df.withColumn(\n",
    "    \"within_1_year\",\n",
    "    f.when((f.col(\"date\") <= f.col(\"T0\")) & (f.col(\"date\") > f.date_sub(f.col(\"T0\"), 365)), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Marquer les jours avec consommation nulle\n",
    "df = df.withColumn(\n",
    "    \"is_null\", f.when((f.col(\"within_1_year\") == 1) & (f.col(\"volume_l_value\") == 0), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier les débuts et fins de périodes de consommation nulle\n",
    "window_spec = Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\")\n",
    "df = df.withColumn(\n",
    "    \"prev_is_null\", f.lag(\"is_null\").over(window_spec)\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"new_null_period\",\n",
    "    f.when((f.col(\"is_null\") == 1) & ((f.col(\"prev_is_null\").isNull()) | (f.col(\"prev_is_null\") == 0)), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Attribuer un identifiant unique à chaque période nulle\n",
    "df = df.withColumn(\n",
    "    \"null_period_id\",\n",
    "    f.sum(\"new_null_period\").over(window_spec)\n",
    ")\n",
    "\n",
    "# Calculer la longueur de chaque période nulle\n",
    "null_period_lengths = df.filter(f.col(\"is_null\") == 1).groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\", \"null_period_id\"\n",
    ").agg(f.count(\"date\").alias(\"period_length\"))\n",
    "\n",
    "# Calculer la durée moyenne des périodes nulles\n",
    "avg_null_period_length = null_period_lengths.groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\"\n",
    ").agg(f.avg(\"period_length\").alias(\"V4\"))\n",
    "\n",
    "# Joindre la colonne v4 au dataset principal\n",
    "df = df.join(avg_null_period_length, [\"sensor\", \"servicePoint\", \"transmitter\"], \"left\")\n",
    "\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V4\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|                V4|\n",
      "+------------------+\n",
      "|               8.0|\n",
      "| 9.090909090909092|\n",
      "|              16.7|\n",
      "|2.3333333333333335|\n",
      "|1.8918918918918919|\n",
      "| 5.434782608695652|\n",
      "|3.6206896551724137|\n",
      "|              7.75|\n",
      "|               3.3|\n",
      "|              NULL|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V4\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V5|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2019-01-01|           0.0|  6|\n",
      "|C04AE134021|2020-01-01|          95.0|  6|\n",
      "|C04AE134021|2021-01-01|           7.0|  6|\n",
      "|C04AE134021|2019-02-01|          15.0|  6|\n",
      "|C04AE134021|2020-02-01|         339.0|  6|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier les jours de consommation nulle\n",
    "df = df.withColumn(\n",
    "    \"is_null\", f.when((f.col(\"within_1_year\") == 1) & (f.col(\"volume_l_value\") == 0), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier les débuts de périodes nulles\n",
    "df = df.withColumn(\n",
    "    \"prev_is_null\", f.lag(\"is_null\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"new_null_period\",\n",
    "    f.when((f.col(\"is_null\") == 1) & ((f.col(\"prev_is_null\").isNull()) | (f.col(\"prev_is_null\") == 0)), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier chaque période de consommation nulle avec un ID unique\n",
    "df = df.withColumn(\n",
    "    \"null_period_id\",\n",
    "    f.sum(\"new_null_period\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\"))\n",
    ")\n",
    "\n",
    "# Calculer la longueur de chaque période nulle\n",
    "null_period_lengths = df.filter(f.col(\"is_null\") == 1).groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\", \"null_period_id\"\n",
    ").agg(f.count(\"date\").alias(\"period_length\"))\n",
    "\n",
    "# Trouver la durée maximale des périodes nulles (v5)\n",
    "max_null_period_length = null_period_lengths.groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\"\n",
    ").agg(f.max(\"period_length\").alias(\"V5\"))\n",
    "\n",
    "# Joindre la colonne v5 au dataset principal\n",
    "df = df.join(max_null_period_length, [\"sensor\", \"servicePoint\", \"transmitter\"], \"left\")\n",
    "\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V5\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|  V5|\n",
      "+----+\n",
      "| 113|\n",
      "|  50|\n",
      "|  25|\n",
      "|   6|\n",
      "|   9|\n",
      "|  89|\n",
      "|  48|\n",
      "|  12|\n",
      "|  21|\n",
      "|NULL|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V5\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V6|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2019-01-01|           0.0|250|\n",
      "|C04AE134021|2020-01-01|          95.0|250|\n",
      "|C04AE134021|2021-01-01|           7.0|250|\n",
      "|C04AE134021|2019-02-01|          15.0|250|\n",
      "|C04AE134021|2020-02-01|         339.0|250|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier les jours de consommation non nulle\n",
    "df = df.withColumn(\n",
    "    \"is_non_null\", f.when((f.col(\"within_1_year\") == 1) & (f.col(\"volume_l_value\") > 0), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier les débuts de périodes non nulles\n",
    "df = df.withColumn(\n",
    "    \"prev_is_non_null\", f.lag(\"is_non_null\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\"))\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"new_non_null_period\",\n",
    "    f.when((f.col(\"is_non_null\") == 1) & ((f.col(\"prev_is_non_null\").isNull()) | (f.col(\"prev_is_non_null\") == 0)), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier chaque période de consommation non nulle avec un ID unique\n",
    "df = df.withColumn(\n",
    "    \"non_null_period_id\",\n",
    "    f.sum(\"new_non_null_period\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\"))\n",
    ")\n",
    "\n",
    "# Calculer la longueur de chaque période non nulle\n",
    "non_null_period_lengths = df.filter(f.col(\"is_non_null\") == 1).groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\", \"non_null_period_id\"\n",
    ").agg(f.count(\"date\").alias(\"non_null_period_length\"))\n",
    "\n",
    "# Trouver la durée maximale des périodes non nulles (v6)\n",
    "max_non_null_period_length = non_null_period_lengths.groupBy(\n",
    "    \"sensor\", \"servicePoint\", \"transmitter\"\n",
    ").agg(f.max(\"non_null_period_length\").alias(\"V6\"))\n",
    "\n",
    "# Joindre la colonne v6 au dataset principal\n",
    "df = df.join(max_non_null_period_length, [\"sensor\", \"servicePoint\", \"transmitter\"], \"left\")\n",
    "\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V6\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| V6|\n",
      "+---+\n",
      "|270|\n",
      "|858|\n",
      "|250|\n",
      "|375|\n",
      "|301|\n",
      "|540|\n",
      "|323|\n",
      "|176|\n",
      "|117|\n",
      "| 91|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V6\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---------+\n",
      "|     sensor|      date|volume_l_value|       V7|\n",
      "+-----------+----------+--------------+---------+\n",
      "|C04AE134021|2019-01-01|           0.0|7070442.0|\n",
      "|C04AE134021|2019-01-02|          61.0|7070442.0|\n",
      "|C04AE134021|2019-01-03|           7.0|7070442.0|\n",
      "|C04AE134021|2019-01-04|           5.0|7070442.0|\n",
      "|C04AE134021|2019-01-05|           3.0|7070442.0|\n",
      "+-----------+----------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier l'index mécanique à la dernière consommation significative (T0)\n",
    "window_spec = Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\").rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "# Filtrer pour récupérer la valeur de l'index à T0\n",
    "df = df.withColumn(\n",
    "    \"v7\",\n",
    "    f.when(f.col(\"date\") == f.col(\"T0\"), f.col(\"index_interpolated_d_l_value\")).otherwise(None)\n",
    ")\n",
    "\n",
    "# Propager l'index mécanique (v7) pour chaque triplette\n",
    "df = df.withColumn(\n",
    "    \"v7\", f.last(\"v7\", ignorenulls=True).over(window_spec)\n",
    ")\n",
    "\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V7\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|       V7|\n",
      "+---------+\n",
      "| 426294.0|\n",
      "|2811627.0|\n",
      "|3526318.0|\n",
      "|7070442.0|\n",
      "| 543614.0|\n",
      "|2252939.5|\n",
      "|1694238.0|\n",
      "| 600791.2|\n",
      "|1208589.0|\n",
      "|2100873.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V7\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---+\n",
      "|     sensor|      date|volume_l_value| V8|\n",
      "+-----------+----------+--------------+---+\n",
      "|C04AE134021|2019-01-01|           0.0| 37|\n",
      "|C04AE134021|2019-01-02|          61.0| 37|\n",
      "|C04AE134021|2019-01-03|           7.0| 37|\n",
      "|C04AE134021|2019-01-04|           5.0| 37|\n",
      "|C04AE134021|2019-01-05|           3.0| 37|\n",
      "+-----------+----------+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identifier les jours de consommation non nulle dans l'année précédant T0\n",
    "df = df.withColumn(\n",
    "    \"is_non_null\", f.when((f.col(\"within_1_year\") == 1) & (f.col(\"volume_l_value\") > 0), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Identifier les débuts de périodes non nulles\n",
    "window_spec = Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\").orderBy(\"date\")\n",
    "df = df.withColumn(\n",
    "    \"prev_is_non_null\", f.lag(\"is_non_null\").over(window_spec)\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"new_non_null_period\",\n",
    "    f.when((f.col(\"is_non_null\") == 1) & ((f.col(\"prev_is_non_null\").isNull()) | (f.col(\"prev_is_non_null\") == 0)), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Calculer le nombre total de périodes non nulles (v8)\n",
    "df = df.withColumn(\n",
    "    \"V8\", f.sum(\"new_non_null_period\").over(Window.partitionBy(\"sensor\", \"servicePoint\", \"transmitter\"))\n",
    ")\n",
    "\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"V8\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| V8|\n",
      "+---+\n",
      "| 34|\n",
      "| 33|\n",
      "|  5|\n",
      "|  1|\n",
      "| 37|\n",
      "| 11|\n",
      "| 30|\n",
      "| 91|\n",
      "| 47|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V8\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+---------+---------+---+\n",
      "|     sensor|      date|volume_l_value|Millesime|       V7| V9|\n",
      "+-----------+----------+--------------+---------+---------+---+\n",
      "|C04AE134021|2019-01-01|           0.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-02|          61.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-03|           7.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-04|           5.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-05|           3.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-06|        1200.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-07|        1076.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-08|        2346.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-09|        4533.0|    C04AE|7070442.0|  2|\n",
      "|C04AE134021|2019-01-10|        1165.0|    C04AE|7070442.0|  2|\n",
      "+-----------+----------+--------------+---------+---------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consumption_features = [\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]\n",
    "millesime_0 = ['C10FA','C10LA','C10SA', 'C11FA','C11LA','C11SA']\n",
    "millesime_1 = ['D16BU', 'Z12ER', 'C07AA']\n",
    "\n",
    "# Extraire les 5 premiers caractères du champ sensor pour obtenir le millesime\n",
    "df = df.withColumn(\"Millesime\", f.substring(f.col(\"sensor\"), 1, 5))\n",
    "\n",
    "df = df.withColumn(\n",
    "    'V9',\n",
    "    f.when(\n",
    "        (df['Millesime'].isin(millesime_0)) & (f.length(f.col('V7').cast(\"string\"))>3),\n",
    "        0\n",
    "    ).otherwise(\n",
    "        f.when(\n",
    "            df['Millesime'].isin(millesime_1),\n",
    "            1\n",
    "        ).otherwise(2)\n",
    "    )\n",
    ")\n",
    "df.select(\"sensor\", \"date\", \"volume_l_value\", \"Millesime\", \"V7\", \"V9\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| V9|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"V9\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make predictons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+\n",
      "|     sensor|servicePoint|transmitter|   client|      date|meterDiameter|volume_l_value|index_interpolated_d_l_value|         T|significant_consumption|        T0| V1|last_significant_date|within_90_days|non_null_days|total_non_null_days| V2|within_183_days|non_null_days_v3|total_non_null_days_v3| V3|within_1_year|is_null|prev_is_null|new_null_period|null_period_id| V4| V5|is_non_null|prev_is_non_null|new_non_null_period|non_null_period_id| V6|     V7| V8|Millesime| V9|\n",
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-02|           40|          61.0|                   5623306.0|2021-08-08|                      1|2019-01-02|730|           2019-01-02|             1|            1|                856|  9|              0|               0|                     0|  0|            1|      0|           1|              0|             1|  1|  6|          1|               0|                  1|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-03|           40|           7.0|                   5623367.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                855|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-04|           40|           5.0|                   5623374.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                854|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-05|           40|           3.0|                   5623379.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                853|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-06|           40|        1200.0|                   5623382.0|2021-08-08|                      1|2019-01-06|949|           2019-01-06|             1|            1|                852|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-07|           40|        1076.0|                   5624582.0|2021-08-08|                      1|2019-01-07|945|           2019-01-07|             1|            1|                851|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-08|           40|        2346.0|                   5625658.0|2021-08-08|                      1|2019-01-08|944|           2019-01-08|             1|            1|                850|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-09|           40|        4533.0|                   5628004.0|2021-08-08|                      1|2019-01-09|943|           2019-01-09|             1|            1|                849|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-10|           40|        1165.0|                   5632537.0|2021-08-08|                      1|2019-01-10|942|           2019-01-10|             1|            1|                848|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-11|           40|           7.0|                   5633702.0|2021-08-08|                      0|2019-01-13|941|           2019-01-13|             1|            1|                847|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-12|           40|          11.0|                   5633709.0|2021-08-08|                      0|2019-01-13|941|           2019-01-13|             1|            1|                846|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-13|           40|        1614.0|                   5633720.0|2021-08-08|                      1|2019-01-13|941|           2019-01-13|             1|            1|                845|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-14|           40|        1229.0|                   5635334.0|2021-08-08|                      1|2019-01-14|938|           2019-01-14|             1|            1|                844|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-15|           40|          66.0|                   5636563.0|2021-08-08|                      1|2019-01-15|937|           2019-01-15|             1|            1|                843|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-16|           40|        1005.0|                   5636629.0|2021-08-08|                      1|2019-01-16|936|           2019-01-16|             1|            1|                842|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-17|           40|        1083.0|                   5637634.0|2021-08-08|                      1|2019-01-17|935|           2019-01-17|             1|            1|                841|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-18|           40|          11.0|                   5638717.0|2021-08-08|                      0|2019-01-20|934|           2019-01-20|             1|            1|                840|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-19|           40|           8.0|                   5638728.0|2021-08-08|                      0|2019-01-20|934|           2019-01-20|             1|            1|                839|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-20|           40|        1155.0|                   5638736.0|2021-08-08|                      1|2019-01-20|934|           2019-01-20|             1|            1|                838|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-21|           40|        1228.0|                   5639891.0|2021-08-08|                      1|2019-01-21|931|           2019-01-21|             1|            1|                837|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|\n",
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consumption_features = [\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]\n",
    "\n",
    "# df = df.select(consumption_features)\n",
    "df = cast_col(df, consumption_features, \"integer\")\n",
    "df = df.dropna()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model for predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel\n",
    "\n",
    "# Load model\n",
    "loaded_model = GBTClassificationModel.load(\"./bestmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+--------------------+\n",
      "|     sensor|servicePoint|transmitter|   client|      date|meterDiameter|volume_l_value|index_interpolated_d_l_value|         T|significant_consumption|        T0| V1|last_significant_date|within_90_days|non_null_days|total_non_null_days| V2|within_183_days|non_null_days_v3|total_non_null_days_v3| V3|within_1_year|is_null|prev_is_null|new_null_period|null_period_id| V4| V5|is_non_null|prev_is_non_null|new_non_null_period|non_null_period_id| V6|     V7| V8|Millesime| V9|            features|\n",
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+--------------------+\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-02|           40|          61.0|                   5623306.0|2021-08-08|                      1|2019-01-02|730|           2019-01-02|             1|            1|                856|  9|              0|               0|                     0|  0|            1|      0|           1|              0|             1|  1|  6|          1|               0|                  1|                 1|250|7070442| 37|    C04AE|  2|[730.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-03|           40|           7.0|                   5623367.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                855|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[949.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-04|           40|           5.0|                   5623374.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                854|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[949.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-05|           40|           3.0|                   5623379.0|2021-08-08|                      0|2019-01-06|949|           2019-01-06|             1|            1|                853|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[949.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-06|           40|        1200.0|                   5623382.0|2021-08-08|                      1|2019-01-06|949|           2019-01-06|             1|            1|                852|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[949.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-07|           40|        1076.0|                   5624582.0|2021-08-08|                      1|2019-01-07|945|           2019-01-07|             1|            1|                851|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[945.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-08|           40|        2346.0|                   5625658.0|2021-08-08|                      1|2019-01-08|944|           2019-01-08|             1|            1|                850|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[944.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-09|           40|        4533.0|                   5628004.0|2021-08-08|                      1|2019-01-09|943|           2019-01-09|             1|            1|                849|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[943.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-10|           40|        1165.0|                   5632537.0|2021-08-08|                      1|2019-01-10|942|           2019-01-10|             1|            1|                848|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[942.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-11|           40|           7.0|                   5633702.0|2021-08-08|                      0|2019-01-13|941|           2019-01-13|             1|            1|                847|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[941.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-12|           40|          11.0|                   5633709.0|2021-08-08|                      0|2019-01-13|941|           2019-01-13|             1|            1|                846|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[941.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-13|           40|        1614.0|                   5633720.0|2021-08-08|                      1|2019-01-13|941|           2019-01-13|             1|            1|                845|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[941.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-14|           40|        1229.0|                   5635334.0|2021-08-08|                      1|2019-01-14|938|           2019-01-14|             1|            1|                844|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[938.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-15|           40|          66.0|                   5636563.0|2021-08-08|                      1|2019-01-15|937|           2019-01-15|             1|            1|                843|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[937.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-16|           40|        1005.0|                   5636629.0|2021-08-08|                      1|2019-01-16|936|           2019-01-16|             1|            1|                842|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[936.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-17|           40|        1083.0|                   5637634.0|2021-08-08|                      1|2019-01-17|935|           2019-01-17|             1|            1|                841|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[935.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-18|           40|          11.0|                   5638717.0|2021-08-08|                      0|2019-01-20|934|           2019-01-20|             1|            1|                840|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[934.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-19|           40|           8.0|                   5638728.0|2021-08-08|                      0|2019-01-20|934|           2019-01-20|             1|            1|                839|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[934.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-20|           40|        1155.0|                   5638736.0|2021-08-08|                      1|2019-01-20|934|           2019-01-20|             1|            1|                838|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[934.0,9.0,0.0,1....|\n",
      "|C04AE134021| 9,84588E+11|   C01E00D9|LYONNAISE|2019-01-21|           40|        1228.0|                   5639891.0|2021-08-08|                      1|2019-01-21|931|           2019-01-21|             1|            1|                837|  9|              0|               0|                     0|  0|            1|      0|           0|              0|             1|  1|  6|          1|               1|                  0|                 1|250|7070442| 37|    C04AE|  2|[931.0,9.0,0.0,1....|\n",
      "+-----------+------------+-----------+---------+----------+-------------+--------------+----------------------------+----------+-----------------------+----------+---+---------------------+--------------+-------------+-------------------+---+---------------+----------------+----------------------+---+-------------+-------+------------+---------------+--------------+---+---+-----------+----------------+-------------------+------------------+---+-------+---+---------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Créer le VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=consumption_features, outputCol=\"features\")\n",
    "\n",
    "# Appliquer la transformation pour créer la colonne \"features\"\n",
    "X_features = assembler.transform(df)\n",
    "\n",
    "# Afficher les données transformées\n",
    "X_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|            features|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|[730.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[949.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[949.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[949.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[949.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[945.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[944.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[943.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[942.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[941.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[941.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[941.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[938.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[937.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[936.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[935.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[934.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[934.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[934.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "|[931.0,9.0,0.0,1....|       0.0|[0.97984154434007...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predicition on new data\n",
    "predictions = gb_model.transform(X_features)\n",
    "\n",
    "predictions.select(\"features\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predicitons into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# - BLOCKED: 0  \n",
    "# - STOPPED: 1\n",
    "predictions = predictions.withColumn(\n",
    "    \"predicited_label\",\n",
    "    f.when(\n",
    "        f.col(\"prediction\") == 0.0,\n",
    "        \"BLOCKED\"\n",
    "    ).otherwise(\"STOPPED\")\n",
    ")\n",
    "\n",
    "selected_columns = [\"sensor\", \"servicePoint\", \"transmitter\", \"date\", \"volume_l_value\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"predicited_label\"]\n",
    "predictions = predictions.select(selected_columns)\n",
    "\n",
    "\n",
    "# save predicitions into csv file\n",
    "predictions.coalesce(1).write.csv(\"./predictions\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1735:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|predicited_label|count(1)|\n",
      "+----------------+--------+\n",
      "|         BLOCKED|    4983|\n",
      "|         STOPPED|    2171|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"predicited_label\").agg(f.count(\"*\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
